{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aquatic-video",
   "metadata": {},
   "source": [
    "### Necessary Packages\n",
    "\n",
    "These are the necessary packages for voice recognition (i.e. vosk and some other things) as well as interpreting the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "emotional-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant packages\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import json\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import numpy as np\n",
    "\n",
    "SetLogLevel(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-learning",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Develop functions to convert signal from Vox to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "popular-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some relevant functions...\n",
    "\n",
    "# table of  quantizer step size\n",
    "StepSizeTable = [16, 17, 19, 21, 23, 25, 28, 31, 34, 37, 41,\n",
    "                 45, 50, 55, 60, 66, 73, 80, 88, 97, 107, 118, 130, 143, 157, 173,\n",
    "                 190, 209, 230, 253, 279, 307, 337, 371, 408, 449, 494, 544, 598, 658,\n",
    "                 724, 796, 876, 963, 1060, 1166, 1282, 1408, 1552]\n",
    "\n",
    "# another conversion table\n",
    "IndexTable = [-1, -1, -1, -1, 2, 4, 6, 8]\n",
    "\n",
    "\n",
    "def ADPCM_Encode(sample):\n",
    "    global index\n",
    "    global predsample\n",
    "\n",
    "    code = 0\n",
    "\n",
    "    step_size = StepSizeTable[index]\n",
    "\n",
    "    # compute diff and record sign and absolut value\n",
    "    diff = sample - predsample\n",
    "    if diff < 0:\n",
    "        code = 8\n",
    "        diff = -diff\n",
    "\n",
    "    # quantize the diff into ADPCM code\n",
    "    # inverse quantize the code into a predicted diff\n",
    "    tmpstep = step_size\n",
    "    diffq = step_size >> 3\n",
    "\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x04\n",
    "        diff -= tmpstep\n",
    "        diffq = diffq + step_size\n",
    "\n",
    "    tmpstep = tmpstep >> 1\n",
    "\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x02\n",
    "        diff = diff - tmpstep\n",
    "        diffq = diffq + (step_size >> 1)\n",
    "\n",
    "    tmpstep = tmpstep >> 1\n",
    "\n",
    "    if diff >= tmpstep:\n",
    "        code = code | 0x01\n",
    "        diffq = diffq + (step_size >> 2)\n",
    "\n",
    "    # fixed predictor to get new predicted sample\n",
    "    if code & 8:\n",
    "        predsample = predsample - diffq\n",
    "    else:\n",
    "        predsample = predsample + diffq\n",
    "\n",
    "    # check for overflow\n",
    "    if predsample > 32767:\n",
    "        predsample = 32767\n",
    "    elif predsample < -32768:\n",
    "        predsample = -32768\n",
    "\n",
    "    # find new stepsize index\n",
    "    index += IndexTable[code]\n",
    "\n",
    "    # check for overflow\n",
    "    if index < 0:\n",
    "        index = 0\n",
    "\n",
    "    if index > 48:\n",
    "        index = 48\n",
    "\n",
    "    # return new ADPCM code   code & 0x0f == code\n",
    "    return code & 0x0f\n",
    "\n",
    "\n",
    "# ADPCM_Decode.\n",
    "# code: a byte containing a 4-bit ADPCM sample.\n",
    "# retval : 16-bit ADPCM sample\n",
    "de_index = 0\n",
    "de_predsample = 0\n",
    "\n",
    "def ADPCM_Decode(code):\n",
    "    global de_index\n",
    "    global de_predsample\n",
    "\n",
    "    step_size = StepSizeTable[de_index]\n",
    "\n",
    "    # inverse code into diff\n",
    "    diffq = step_size >> 3  # == step/8\n",
    "    if code & 4:\n",
    "        diffq += step_size\n",
    "\n",
    "    if code & 2:\n",
    "        diffq += step_size >> 1\n",
    "\n",
    "    if code & 1:\n",
    "        diffq += step_size >> 2\n",
    "\n",
    "    # add diff to predicted sample\n",
    "    if code & 8:\n",
    "        diffq = -diffq\n",
    "\n",
    "    de_predsample += diffq\n",
    "\n",
    "    # check for overflow  clip the values to +/- 2^11 (supposed to be 16 bits)\n",
    "    if de_predsample > 2047:\n",
    "        de_predsample = 2047\n",
    "    elif de_predsample < -2048:\n",
    "        de_predsample = -2048\n",
    "\n",
    "    # find new quantizer step size\n",
    "    de_index += IndexTable[code]\n",
    "\n",
    "    # check for overflow\n",
    "    if de_index < 0:\n",
    "        de_index = 0\n",
    "\n",
    "    if de_index > 48:\n",
    "        de_index = 48\n",
    "\n",
    "    # save predict sample and de_index for next iteration\n",
    "    # return new decoded sample\n",
    "    # The original algorithm turned out to be 12bit, need to convert to 16bit\n",
    "    return de_predsample << 4\n",
    "\n",
    "def decodeTBS2(list_8bit):\n",
    "    list_16bit = []\n",
    "    for i in range(len(list_8bit)):\n",
    "        byte_i = list_8bit[i]  # 1 bytes = 8bit\n",
    "        high_4bit = (byte_i & 0xf0) >> 4  # split high 4bit from 8bit\n",
    "        low_4bit = byte_i & 0x0f  # split low 4bit from 8bit\n",
    "\n",
    "        # first sample\n",
    "        sample_0 = high_4bit\n",
    "        # unsigned to signed\n",
    "        # 4bit : -2^4 ~ 2^(4-1)-1\n",
    "        if sample_0 > 7:\n",
    "            sample_4bit_0 = sample_0 - 16\n",
    "        else:\n",
    "            sample_4bit_0 = sample_0\n",
    "\n",
    "        # second sample\n",
    "        sample_1 = low_4bit\n",
    "        # unsigned to signed\n",
    "        if sample_1 > 7:\n",
    "            sample_4bit_1 = sample_1 - 16\n",
    "        else:\n",
    "            sample_4bit_1 = sample_1\n",
    "\n",
    "        # now decode\n",
    "        tmpDeS16_0 = ADPCM_Decode(sample_4bit_0)\n",
    "        tmpDeS16_1 = ADPCM_Decode(sample_4bit_1)\n",
    "\n",
    "        list_16bit.extend([tmpDeS16_0, tmpDeS16_1])\n",
    "        \n",
    "    # decoded data\n",
    "    return list_16bit\n",
    "\n",
    "# make sure that list_16bit is a numpy array!\n",
    "def toWav(list_16bit, name):\n",
    "    wav_file = wave.open(name + '.wav', 'wb')\n",
    "\n",
    "    # configure channel number, quantization size, and sample rate\n",
    "    wav_file.setnchannels(1)\n",
    "    wav_file.setsampwidth(2)\n",
    "    wav_file.setframerate(16000)\n",
    "    # converts data to binary data and writes it to a file\n",
    "    wav_file.writeframes(list_16bit.tobytes())\n",
    "    wav_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-penalty",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Filter audio signals..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baking-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered(list_16bit):\n",
    "    sos = signal.butter(10, [4000], 'lowpass', fs=16000, output='sos')\n",
    "    return signal.sosfilt(sos, list_16bit)\n",
    "\n",
    "def toWav(list_16bit, name):\n",
    "    wav_file = wave.open(name + '.wav', 'wb')\n",
    "\n",
    "    # configure channel number, quantization size, and sample rate\n",
    "    wav_file.setnchannels(1)\n",
    "    wav_file.setsampwidth(2)\n",
    "    wav_file.setframerate(16000)\n",
    "    # converts data to binary data and writes it to a file\n",
    "    wav_file.writeframes(list_16bit.tobytes())\n",
    "    wav_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-baking",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Convert audio data to text through Vox and compare to preset commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "controversial-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert audio from a wavefile e.g. \"example.wav\" to \n",
    "def wav2str(filename):\n",
    "    sample_rate=16000\n",
    "    # this should be the name\n",
    "    model = Model(\"modelsmall\")\n",
    "    rec = KaldiRecognizer(model, sample_rate)\n",
    "\n",
    "    wf = wave.open(filename, \"rb\")\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        print (\"Audio file must be WAV format mono PCM.\")\n",
    "        exit (1)\n",
    "\n",
    "\n",
    "    results = []\n",
    "    subs = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            results.append(rec.Result())\n",
    "    results.append(rec.FinalResult())\n",
    "\n",
    "    Strings = []\n",
    "    for i, res in enumerate(results):\n",
    "        jres = json.loads(res)\n",
    "        if not 'result' in jres:\n",
    "            continue\n",
    "        words = jres['result']\n",
    "        for j in range(len(words)):\n",
    "            Strings.append(words[j]['word'])\n",
    "        \n",
    "    return Strings\n",
    "\n",
    "# to compare two lists\n",
    "def edit_dist(A, B):\n",
    "    if len(A) <= len(B):                 # convenient notation to organize\n",
    "        shorter,longer = A,B\n",
    "    else:\n",
    "        shorter,longer = B,A\n",
    "\n",
    "    a = np.zeros((2,len(shorter) + 1), dtype=int) # matrix of values\n",
    "    \n",
    "    # get the first row\n",
    "    for i in range(len(shorter)+1):\n",
    "        a[0][i] = i                      # 0th row\n",
    "    \n",
    "    # get the rest of the rows\n",
    "    for j in range(1,len(longer)+1):\n",
    "        a[1][0] = j                          # first column\n",
    "        for i in range(1,len(shorter)+1):\n",
    "            a[1][i] = min([a[0][i-1] + (longer[j-1] != shorter[i-1]),\n",
    "                           a[0][i] + 1,\n",
    "                           a[1][i-1] + 1])\n",
    "        a[0] = a[1]                          # push row back\n",
    "    \n",
    "    return(a[0][len(shorter)])           # return last value\n",
    "\n",
    "# a method for comparing two lists of strings\n",
    "# there are other ways this could be implemented\n",
    "# this is just one way that worked\n",
    "def list_compare(L1,L2):\n",
    "    if not len(L1) and not len(L2):\n",
    "        return 0\n",
    "    \n",
    "    D = np.zeros((len(L1)+1,len(L2)+1))\n",
    "    for i in range(len(L1)):\n",
    "        D[i+1,0] = i+1\n",
    "    for j in range(len(L2)):\n",
    "        D[0,j+1] = j+1\n",
    "        \n",
    "        \n",
    "    for i in range(1,len(L1)+1):\n",
    "        for j in range(1,len(L2)+1):\n",
    "            D[i,j] = min([D[i-1][j-1] + edit_dist(L1[i-1],L2[j-1])/max(len(L1[i-1]),len(L2[j-1])),\n",
    "                           D[i-1][j] + 1,\n",
    "                           D[i][j-1] + 1])\n",
    "    return D[len(L1),len(L2)]/max(len(L1),len(L2))\n",
    "\n",
    "# returns -1 for error otherwise returns index of input\n",
    "def Select_Command(Input, Commands, Threshold = 0.33):\n",
    "    argMax, Max = -1, 0\n",
    "    for i in range(len(Commands)):\n",
    "        Similarity = 0\n",
    "        for j in range(len(Commands[i])):\n",
    "            Similarity = Similarity + (1-list_compare(Input,Commands[i][j]))\n",
    "        Similarity = Similarity / len(Commands[i])\n",
    "        if Similarity > Max and Similarity > Threshold:\n",
    "            argMax, Max = i, Similarity\n",
    "    return argMax\n",
    "    \n",
    "\n",
    "# list of new commands. Normally we would do this over Thread \n",
    "# but I am doing this manually with nothing under my sleeve \n",
    "# (first run through) in order to make the test faster\n",
    "\n",
    "# 'test command one' \n",
    "Command_One = [['just', 'one'],\n",
    "              ['test', 'one'],\n",
    "              ['test', 'command', 'one'],\n",
    "              ['test', 'to', 'man', 'one'],\n",
    "              ['test', 'man', 'one']]\n",
    "# 'some long sentence'\n",
    "Command_Two = [['some', 'one', 'sentence'],\n",
    "              ['some', 'sentence'],\n",
    "              ['the', 'sentence'],\n",
    "              ['some', 'long', 'sentence'],\n",
    "              ['some', 'sentence']]\n",
    "# 'dog' - corner case short command\n",
    "Command_Three = [['dog'], ['dog'],\n",
    "                [], [],\n",
    "                ['talk']]\n",
    "# 'test command four' - corner case similar commands\n",
    "Command_Four = [['test', 'command'],\n",
    "               ['command', 'for'],\n",
    "               ['test', 'command', 'for'],\n",
    "               ['test', 'in', 'for'],\n",
    "               ['just', 'coming']] # the last one makes absolutely no sense but there yah go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-tuesday",
   "metadata": {},
   "source": [
    "### Actual Implementation\n",
    "\n",
    "Code below used to generate file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "environmental-stamp",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Recordings/command4e.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c8a1770c49c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.log'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Recordings/command4e.log'"
     ]
    }
   ],
   "source": [
    "# read from file, any other way to get 8-bit encoded data works\n",
    "filename = 'Recordings/command4e'\n",
    "\n",
    "test = []\n",
    "with open(filename + '.log', \"rb\") as file:\n",
    "    test.extend(file.read())\n",
    "    \n",
    "RawPCM = np.array(decodeTBS2(test),dtype=np.int16)[1500:]\n",
    "# filtering with this method just makes it worse... \n",
    "# look into other methods like Riley suggested or accept the error for now...\n",
    "# This is quite unfortunate so far\n",
    "Filtered = filtered(RawPCM)\n",
    "\n",
    "# convert to wav file\n",
    "toWav(RawPCM,filename)\n",
    "\n",
    "# read file and translate through vosk\n",
    "wav2str(filename + '.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "invalid-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True [['just', 'one'], ['test', 'one'], ['test', 'command', 'one'], ['test', 'to', 'man', 'one'], ['test', 'man', 'one']]\n",
      "True [['some', 'one', 'sentence'], ['some', 'sentence'], ['the', 'sentence'], ['some', 'long', 'sentence'], ['some', 'sentence']]\n",
      "False [['test', 'command'], ['command', 'for'], ['test', 'command', 'for'], ['test', 'in', 'for'], ['just', 'coming']]\n",
      "True [['test', 'command'], ['command', 'for'], ['test', 'command', 'for'], ['test', 'in', 'for'], ['just', 'coming']]\n"
     ]
    }
   ],
   "source": [
    "# test first with intended command\n",
    "Input = [['test', 'command', 'one'], ['some', 'long', 'sentence'], ['dog'], ['test', 'command', 'four']]\n",
    "Commands = [Command_One,Command_Two,Command_Three,Command_Four]\n",
    "for i in range(len(Input)):\n",
    "    index = Select_Command(Input[i],Commands,0.4)\n",
    "    print(i == index,Commands[index])\n",
    "# This works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fallen-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# compare to random commands...\n",
    "Input = [['cat'], ['another', 'command'], ['some', 'other', 'command'], ['test','command', 'five']]\n",
    "Commands = [Command_One,Command_Two,Command_Three,Command_Four]\n",
    "for i in range(len(Input)):\n",
    "    index = Select_Command(Input[i],Commands,0.4)\n",
    "    print(index == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-passport",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "The true commands are recognizable with a similarity threshold of 0.35. The false commands can be removed with a similarity of 0.55. This forces a dilemma, and we may need better methods. For example, with small strings we can force them to repeat if we get an empty list. Next, we should try comparing these commands to new spoken ones (valid and invalid)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-illness",
   "metadata": {},
   "source": [
    "### Test real commands\n",
    "\n",
    "Below is the result of recorded commands vs recorded commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "effective-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pest', 'command', 'point']\n",
      "3 [['test', 'command'], ['command', 'for'], ['test', 'command', 'for'], ['test', 'in', 'for'], ['just', 'coming']]\n",
      "similarity: 0.470952380952381\n"
     ]
    }
   ],
   "source": [
    "filename = 'Recordings/one'\n",
    "\n",
    "test = []\n",
    "with open(filename + '.log', \"rb\") as file:\n",
    "    test.extend(file.read())\n",
    "    \n",
    "RawPCM = np.array(decodeTBS2(test),dtype=np.int16)[1500:]\n",
    "\n",
    "# convert to wav file\n",
    "toWav(RawPCM,filename)\n",
    "\n",
    "# read file and translate through vosk\n",
    "result = wav2str(filename + '.wav')\n",
    "print(result)\n",
    "\n",
    "Commands = [Command_One,Command_Two,Command_Three,Command_Four]\n",
    "index = Select_Command(result,Commands,.4)\n",
    "\n",
    "return index\n",
    "\n",
    "# print(index,Commands[index])\n",
    "\n",
    "# S = 0\n",
    "# for i in range(5):\n",
    "#     S = S+(list_compare(result,Commands[index][i]))\n",
    "# print('similarity: ' + str(1-S/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "waiting-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some', 'on', 'sentence']\n",
      "1 [['some', 'one', 'sentence'], ['some', 'sentence'], ['the', 'sentence'], ['some', 'long', 'sentence'], ['some', 'sentence']]\n",
      "similarity: 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "filename = 'Recordings/two'\n",
    "\n",
    "test = []\n",
    "with open(filename + '.log', \"rb\") as file:\n",
    "    test.extend(file.read())\n",
    "    \n",
    "RawPCM = np.array(decodeTBS2(test),dtype=np.int16)[1500:]\n",
    "\n",
    "# convert to wav file\n",
    "toWav(RawPCM,filename)\n",
    "\n",
    "# read file and translate through vosk\n",
    "result = wav2str(filename + '.wav')\n",
    "print(result)\n",
    "\n",
    "Commands = [Command_One,Command_Two,Command_Three,Command_Four]\n",
    "index = Select_Command(result,Commands,.4)\n",
    "\n",
    "print(index,Commands[index])\n",
    "\n",
    "S = 0\n",
    "for i in range(5):\n",
    "    S = S+(list_compare(result,Commands[index][i]))\n",
    "print('similarity: ' + str(1-S/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "protective-parish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "2 [['dog'], ['dog'], [], [], ['talk']]\n",
      "similarity: 0.4\n"
     ]
    }
   ],
   "source": [
    "filename = 'Recordings/three'\n",
    "\n",
    "test = []\n",
    "with open(filename + '.log', \"rb\") as file:\n",
    "    test.extend(file.read())\n",
    "    \n",
    "RawPCM = np.array(decodeTBS2(test),dtype=np.int16)[1500:]\n",
    "\n",
    "# convert to wav file\n",
    "toWav(RawPCM,filename)\n",
    "\n",
    "# read file and translate through vosk\n",
    "result = wav2str(filename + '.wav')\n",
    "print(result)\n",
    "\n",
    "Commands = [Command_One,Command_Two,Command_Three,Command_Four]\n",
    "index = Select_Command(result,Commands)\n",
    "\n",
    "print(index,Commands[index])\n",
    "\n",
    "S = 0\n",
    "for i in range(5):\n",
    "    S = S+(list_compare(result,Commands[index][i]))\n",
    "print('similarity: ' + str(1-S/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "excessive-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'plan', 'for']\n",
      "3 [['test', 'command'], ['command', 'for'], ['test', 'command', 'for'], ['test', 'in', 'for'], ['just', 'coming']]\n",
      "similarity: 0.5182539682539682\n"
     ]
    }
   ],
   "source": [
    "filename = 'Recordings/four'\n",
    "\n",
    "test = []\n",
    "with open(filename + '.log', \"rb\") as file:\n",
    "    test.extend(file.read())\n",
    "    \n",
    "RawPCM = np.array(decodeTBS2(test),dtype=np.int16)[1500:]\n",
    "\n",
    "# convert to wav file\n",
    "toWav(RawPCM,filename)\n",
    "\n",
    "# read file and translate through vosk\n",
    "result = wav2str(filename + '.wav')\n",
    "print(result)\n",
    "\n",
    "Commands = [Command_One,Command_Two,Command_Three,Command_Four]\n",
    "index = Select_Command(result,Commands,.4)\n",
    "\n",
    "print(index,Commands[index])\n",
    "\n",
    "S = 0\n",
    "for i in range(5):\n",
    "    S = S+(list_compare(result,Commands[index][i]))\n",
    "print('similarity: ' + str(1-S/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-myrtle",
   "metadata": {},
   "source": [
    "### Further notes\n",
    "\n",
    "This did fantastic! However, both corner cases caught this program. For short inputs we should verify that we got an actual input and not \\[\\]. For similar commands we'll need an improved filter or hardware I believe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
