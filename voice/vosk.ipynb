{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liberal-annotation",
   "metadata": {},
   "source": [
    "### Necessary files\n",
    "\n",
    "This is the audio package Riley mentioned and it's pretty easy so I thought it's worth a shot. You'll need vosk (pip install vosk). This is full on audio recognition but it seemed easier to start here than to distinguish signals...\n",
    "\n",
    "Additionally, you'll need the neural network ideally the small english model which can be found at this [link](https://alphacephei.com/vosk/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "retained-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant packages\n",
    "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import subprocess\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "SetLogLevel(0)\n",
    "\n",
    "if not os.path.exists(\"model\"):\n",
    "    print (\"Please download the model from https://alphacephei.com/vosk/models and unpack as 'model' in the current folder.\")\n",
    "    exit (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-bundle",
   "metadata": {},
   "source": [
    "### Convert input to string\n",
    "\n",
    "The following is the Vosk code to convert our wav files to a list of strings. This assumes the input is one channel with a sampling rate of 16000 and converted out of Vox ADPCM (just to wac or 16 bit PCM). This does fairly well, make sure to add a low pass filter onto the audio. Additionally, I added my code for getting the edit distance because the translation will certainly have errors and it's a good way of comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "polish-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert audio from a wavefile e.g. \"example.wav\" to \n",
    "def wav2str(filename):\n",
    "    sample_rate=16000\n",
    "    # this should be the name\n",
    "    model = Model(\"modelsmall\")\n",
    "    rec = KaldiRecognizer(model, sample_rate)\n",
    "\n",
    "    wf = wave.open(filename, \"rb\")\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
    "        print (\"Audio file must be WAV format mono PCM.\")\n",
    "        exit (1)\n",
    "\n",
    "\n",
    "    results = []\n",
    "    subs = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if rec.AcceptWaveform(data):\n",
    "            results.append(rec.Result())\n",
    "    results.append(rec.FinalResult())\n",
    "\n",
    "    Strings = []\n",
    "    for i, res in enumerate(results):\n",
    "        jres = json.loads(res)\n",
    "        if not 'result' in jres:\n",
    "            continue\n",
    "        words = jres['result']\n",
    "        for j in range(len(words)):\n",
    "            Strings.append(words[j]['word'])\n",
    "        \n",
    "    return Strings\n",
    "\n",
    "# to compare two lists\n",
    "def edit_dist(A, B):\n",
    "    if len(A) <= len(B):                 # convenient notation to organize\n",
    "        shorter,longer = A,B\n",
    "    else:\n",
    "        shorter,longer = B,A\n",
    "\n",
    "    a = np.zeros((2,len(shorter) + 1), dtype=int) # matrix of values\n",
    "    \n",
    "    # get the first row\n",
    "    for i in range(len(shorter)+1):\n",
    "        a[0][i] = i                      # 0th row\n",
    "    \n",
    "    # get the rest of the rows\n",
    "    for j in range(1,len(longer)+1):\n",
    "        a[1][0] = j                          # first column\n",
    "        for i in range(1,len(shorter)+1):\n",
    "            a[1][i] = min([a[0][i-1] + (longer[j-1] != shorter[i-1]),\n",
    "                           a[0][i] + 1,\n",
    "                           a[1][i-1] + 1])\n",
    "        a[0] = a[1]                          # push row back\n",
    "    \n",
    "    return(a[0][len(shorter)])           # return last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "compliant-insulin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sentence', 'number', 'one'] ['a', 'sentence', 'number', 'two'] ['test', 'sentence', 'number', 'three']\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "one,two,three = wav2str('Recordings/tsent1.wav'),wav2str('Recordings/tsent2.wav'),wav2str('Recordings/tsent3.wav')\n",
    "# one and two are close, three is perfect:\n",
    "print(one,two,three)\n",
    "X = [one, two, three ]\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(X)):\n",
    "        print(edit_dist(X[i],X[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "designed-necessity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['one'], ['command', 'one'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# me saying 'test command 1' through TBS2\n",
    "\n",
    "wav2str('Recordings/tbs2test1-1.wav'),wav2str('Recordings/tbs2test1-2.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
